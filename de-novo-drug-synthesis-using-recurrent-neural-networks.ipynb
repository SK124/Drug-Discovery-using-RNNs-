{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "De Novo Drug Synthesis Using Recurrent Neural Networks .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V1uPuBhTS-YFMn32USuM6QwuTo4c5s-L",
      "authorship_tag": "ABX9TyP3I4WOdsoN/+KbEiR6vvpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/SK124/536bf7adcf276f07aad012e5c79ff871/de-novo-drug-synthesis-using-recurrent-neural-networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xC2qulQgUin"
      },
      "source": [
        "###Following work is an Impementaion of the [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5836943/) \"Generative Recurrent Networks for De Novo Drug Design\" - Prof [Schneider Gisbert ](https://www.ncbi.nlm.nih.gov/pubmed/?term=Schneider%20G%5BAuthor%5D&cauthor=true&cauthor_uid=29095571)    et al.###\n",
        "\n",
        "In this approach we are going to leverage on the beneifts of LSTM RNN Units to generate possible drug sequences for fragment‚Äêbased drug discovery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4VwupYYP7_T"
      },
      "source": [
        "NECCESARY IMPORTS FOR PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JznHOVmgFXqm"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF7Nbdmdj6C5"
      },
      "source": [
        "This dataframe consisits of real life drug design sequences which we will use to create our very own language model.\n",
        "The drug sequence is representated in SMILES format. which stands for Simplified Molecular Input Line Entry System. You can read more about SMILES nomenclature [here](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znSSeOiGFv0c",
        "outputId": "cddc3f38-6540-48ef-9789-ced2ea02940b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df=pd.read_csv('/content/full_data_final.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 col\n",
              "0            CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n",
              "1       C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\n",
              "2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...\n",
              "3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...\n",
              "4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcXtZCdzQDyB"
      },
      "source": [
        "* Make a text file including only sequences of size between 70 and 30, as this boundary captures almost all relevant molecules with which we can learn the SMILES syntax tight and train with ease. This boundary gives us the least trade-off between the two.\n",
        " \n",
        " \n",
        "* Token 'G' has been added as start token and Token 'E' is added as End token to denote start point and end point of the all sequences. \n",
        " \n",
        "* Token 'A' is the padding token since not all the sequences are of size 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwqKjpvVnLFd"
      },
      "source": [
        "lengths=[]\n",
        "\n",
        "with open('drug.txt','w') as f:\n",
        "    for i in range(len(df)):\n",
        "        text=df['col'][i]\n",
        "       # if (len(text)<70 and len(text)>30):\n",
        "        lengths.append(len(text))\n",
        "        t=109-len(text)\n",
        "            text='G'+text+'E'\n",
        "            text=text+'A'*t\n",
        "            f.write(text+'\\n')\n",
        "           # df['col'][i]=text\n",
        "           # index.append(i)\n",
        "        \n",
        "    \n",
        "    \n",
        "len(lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clAGNTNJGKlf",
        "outputId": "8ecea710-44af-46c3-9148-b69c7f69841b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lengths=[]\n",
        "\n",
        "with open('drug.txt','w') as f:\n",
        "    for i in range(len(df)):\n",
        "        text=df['col'][i]\n",
        "        if (len(text)<70 and len(text)>30):\n",
        "            lengths.append(len(text))\n",
        "            t=69-len(text)\n",
        "            text='G'+text+'E'\n",
        "            text=text+'A'*t\n",
        "            f.write(text+'\\n')\n",
        "           # df['col'][i]=text\n",
        "           # index.append(i)\n",
        "        \n",
        "    \n",
        "    \n",
        "len(lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S25Qs_ZRKk9"
      },
      "source": [
        "Once we have the text file, we load it as a single string for further preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idns2C-MGVjh"
      },
      "source": [
        "raw_texts=''\n",
        "string=''\n",
        "with open('drug.txt','r') as f:\n",
        "\n",
        "  text=f.readlines()\n",
        "  for tex in text:\n",
        "    tex=tex.strip('\\n')\n",
        "    string+=tex\n",
        "    string=str(string)\n",
        "    \n",
        "  raw_texts=string\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fzGrGWIKqf"
      },
      "source": [
        "raw_texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_UXrwuGRdlq"
      },
      "source": [
        "* unique_chars will contain all the unique tokens\n",
        "char_to_int and int_to_char will contain mappings of tokens with respect to integer and vice versa\n",
        "\n",
        "* We are popping index 15 here from unique_chars list because it has the padding token 'A' included, I wish to give the padding token index 0 which we will do later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_pX4LiBG-jr"
      },
      "source": [
        "unique_chars = sorted(list(set(raw_texts)))\n",
        "unique_chars.pop(15)\n",
        "# maps each unique character as int\n",
        "char_to_int = dict((c, i+1) for i, c in enumerate(unique_chars))\n",
        "\n",
        "\n",
        "int_to_char = dict((i+1, c) for i, c in enumerate(unique_chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6JfHcK2IDGj",
        "outputId": "d8c04c13-2df5-4c33-c2af-cc650883d5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 1,\n",
              " '(': 2,\n",
              " ')': 3,\n",
              " '+': 4,\n",
              " '-': 5,\n",
              " '/': 6,\n",
              " '1': 7,\n",
              " '2': 8,\n",
              " '3': 9,\n",
              " '4': 10,\n",
              " '5': 11,\n",
              " '6': 12,\n",
              " '7': 13,\n",
              " '=': 14,\n",
              " '@': 15,\n",
              " 'B': 16,\n",
              " 'C': 17,\n",
              " 'E': 18,\n",
              " 'F': 19,\n",
              " 'G': 20,\n",
              " 'H': 21,\n",
              " 'I': 22,\n",
              " 'N': 23,\n",
              " 'O': 24,\n",
              " 'P': 25,\n",
              " 'S': 26,\n",
              " '[': 27,\n",
              " '\\\\': 28,\n",
              " ']': 29,\n",
              " 'c': 30,\n",
              " 'l': 31,\n",
              " 'n': 32,\n",
              " 'o': 33,\n",
              " 'r': 34,\n",
              " 's': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viD3IxONHpha",
        "outputId": "fbc7a0d1-68c0-4691-d0cf-c44efbb4c398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mapping_size = len(char_to_int)\n",
        "reverse_mapping_size = len(int_to_char)\n",
        "print (\"Size of the character to integer dictionary is: \", mapping_size)\n",
        "print (\"Size of the integer to character dictionary is: \", reverse_mapping_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the character to integer dictionary is:  35\n",
            "Size of the integer to character dictionary is:  35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK_YcSCUSWgy"
      },
      "source": [
        "Now we need to obtain our SMILES Sequences from the single string, each seqeunce will have a size of 71 after adding the tokens(\"G\" , \"A\" , \"E\" ). we will now load them into a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZlgjaUxH-7A"
      },
      "source": [
        "raw=[]\n",
        "for i in range(len(raw_texts)//71):\n",
        "  string=raw_texts[71*i:71*(i+1)]\n",
        "  string=string.strip('A')\n",
        "  raw.append(string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSHhuIZjJlYU",
        "outputId": "0cf177e8-4f79-47e2-97cd-9918f40a3e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "raw[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgPzgoWzSy59"
      },
      "source": [
        "Now we change the SMILES sequences to its integer representaion, we wil load it in a list for further preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMJNVSDfJnHz"
      },
      "source": [
        "raw_ints=[[char_to_int[w] for w in drug] for drug in raw]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wz7KSymJ8O7",
        "outputId": "dd816644-2d90-4f81-ba78-dfd891a6ae6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "raw_ints[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 17,\n",
              " 17,\n",
              " 2,\n",
              " 17,\n",
              " 3,\n",
              " 2,\n",
              " 17,\n",
              " 3,\n",
              " 30,\n",
              " 7,\n",
              " 30,\n",
              " 30,\n",
              " 30,\n",
              " 8,\n",
              " 33,\n",
              " 30,\n",
              " 30,\n",
              " 2,\n",
              " 17,\n",
              " 17,\n",
              " 2,\n",
              " 14,\n",
              " 24,\n",
              " 3,\n",
              " 23,\n",
              " 30,\n",
              " 9,\n",
              " 30,\n",
              " 30,\n",
              " 30,\n",
              " 30,\n",
              " 30,\n",
              " 9,\n",
              " 19,\n",
              " 3,\n",
              " 30,\n",
              " 8,\n",
              " 30,\n",
              " 7,\n",
              " 18]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiHhnhVJTgzB"
      },
      "source": [
        "* Now we split the string sequnece as X and Y\n",
        " \n",
        "* Our model will predict sequence Y from sequence X\n",
        " \n",
        "* As the authors say in the paper \" The method for training that we used, as shown in Figure, pads every input string to n tokens, where n is the length of the longest SMILES string. For each token, the model predicts the next token in the sequence\"\n",
        " \n", 
        " \n",
        " Follow this [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5836943/figure/minf201700111-fig-0003/) for the image\n",
        " \n",
        " \n",
        "* Sequence length = 71\n",
        " \n",
        "* So,\n",
        " \n",
        " \n",
        " \n",
        "1.   x = first 70 integer values\n",
        "2.   y = last 70 integer values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFQOAvvMKS9U"
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(len(raw_ints)):\n",
        "  x.append(raw_ints[i][:-1])\n",
        "  y.append(raw_ints[i][1:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r8rM6Y-UCF2",
        "outputId": "bf5b7a81-6dd2-476b-f949-165515db396e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKFE9kFTKa7e",
        "outputId": "3e5261fe-fbab-4f5a-b014-5d93cfeb3d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmQTAO_fUc0u"
      },
      "source": [
        "max_words here is timesteps or sequence length which is 70 in our case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUjTRr1kKhv-"
      },
      "source": [
        "max_words=70\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziBvlU4cKuwz",
        "outputId": "f0ab949f-d8a5-4e3e-d76f-00815f7b9304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size=len(char_to_int)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlGnyeLUUKqL"
      },
      "source": [
        "Adding a 1 because we deleted Padding token index from  the list but we need it for integer to string SMILE conversion as it is present in many sequences whose size is less than 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3GEfX08LVv7",
        "outputId": "d1a16d85-6fce-45d0-fc8d-508093d41a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_chars=vocab_size+1\n",
        "n_chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyDJukVcVW55"
      },
      "source": [
        "One Hot encoing the sequence as our model expects a 3D Tensor, we use numpy here to do it in ease, however you can do it yourself, code attached in sampling part of code for the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGZFu7M7Kwxt",
        "outputId": "1d97d7f0-6e44-470f-87fb-8e4f6a0da4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X = np.array([to_categorical(pad_sequences((sent,), max_words),  \n",
        "       n_chars)  for sent in x])\n",
        "X = X[:, 0, :, :]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92967, 70, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxcURe2jK363",
        "outputId": "ee326b7d-7a0d-4b46-da00-cfae557f2f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y = np.array([to_categorical(pad_sequences((sent,), max_words),  \n",
        "       n_chars)  for sent in y])\n",
        "Y=Y[:, 0, :, :]\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92967, 70, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkNGfzCCVsd0"
      },
      "source": [
        "Imports for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-0oXaLqLBzR"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Dense, LSTM, TimeDistributed, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "import keras\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsCFJ1GZVxW8"
      },
      "source": [
        "### MODEL ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5eJ10-hLJ5v"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(None, n_chars)))\n",
        "        \n",
        "model.add(LSTM(256, unit_forget_bias=True, dropout=0.5, \n",
        "                                 return_sequences=True))        \n",
        "model.add(LSTM(256, unit_forget_bias=True, dropout=0.5, \n",
        "                                 return_sequences=True))\n",
        "model.add(BatchNormalization(input_shape=(None, n_chars)))\n",
        "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPuFgy0oMLZp",
        "outputId": "62769dfc-f0f5-4bae-d5b4-151d7e378a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "print (model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, None, 36)          144       \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 256)         300032    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 256)         525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, None, 256)         1024      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 36)          9252      \n",
            "=================================================================\n",
            "Total params: 835,764\n",
            "Trainable params: 835,180\n",
            "Non-trainable params: 584\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VYHAyBCM3N6"
      },
      "source": [
        "mkdir weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5W59ReMOYY",
        "outputId": "8f56a3b7-d2bc-4a0d-8ecd-d54413a7a5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "filepath=\"/content/weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# # Fit the model # epochs supposed to be 50\n",
        "model.fit(X, Y, epochs = 5+3, batch_size = 64, callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "92967/92967 [==============================] - 585s 6ms/step - loss: 0.7045\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.70450, saving model to /content/weights/weights-improvement-01-0.7045.hdf5\n",
            "Epoch 2/3\n",
            "92967/92967 [==============================] - 589s 6ms/step - loss: 0.6938\n",
            "\n",
            "Epoch 00002: loss improved from 0.70450 to 0.69378, saving model to /content/weights/weights-improvement-02-0.6938.hdf5\n",
            "Epoch 3/3\n",
            "92967/92967 [==============================] - 582s 6ms/step - loss: 0.6856\n",
            "\n",
            "Epoch 00003: loss improved from 0.69378 to 0.68559, saving model to /content/weights/weights-improvement-03-0.6856.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f300f8a2d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkALgF6eV1is"
      },
      "source": [
        "Now would be a good time to add back our padding token with index 0 as I wanted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b4hatF0N7oC"
      },
      "source": [
        "int_to_char.update({0:'A'})\n",
        "char_to_int.update({'A':0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmFsyCuIWCZU"
      },
      "source": [
        "SAMPLING STRATEGY "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mw5a8qEWTnd"
      },
      "source": [
        "* Sample funcion takes the start token \"G\", end token \"E\", temperature a parameter which is explained below,also length of desired seqeunce and mappings between both integer and token to convert back the numbers, the model spits the drug seqeunce in integer form and this function therefore returns us sequence in SMILES format, Our model starts generating sequence after we give it the \"G\" token.\n",
        " \n",
        "* It will either stop the sequence before it reaches maximum length (max_len) which is a parameter we can tweak or after encountering \"E\" token which denotes the end of sequence.\n",
        " \n",
        "* It has two helper functions get_token_probas which is better  than the usual argmax we usally do because it brings in variance or temperature as its called in thermodynamics and one_hot_encode function from scratch which we need in sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-2x1GDvNgIb"
      },
      "source": [
        "def one_hot_encode(token_lists, n_chars):\n",
        "    \n",
        "    output = np.zeros((len(token_lists), len(token_lists[0]), n_chars))\n",
        "    for i, token_list in enumerate(token_lists):\n",
        "        for j, token in enumerate(token_list):\n",
        "            output[i, j, int(token)] = 1\n",
        "    return output\n",
        "         \n",
        "def sample(model, temp, start_char, end_char, max_len, indices_token, token_indices):\n",
        "    \n",
        "    n_chars = len(indices_token)\n",
        "\n",
        "    seed_token =  [token_indices[start_char]]\n",
        "    generated = indices_token[int(str(seed_token[0]))]\n",
        "    \n",
        "    \n",
        "    while generated[-1] != end_char:# and len(generated) < max_len:\n",
        "        x_seed = one_hot_encode([seed_token], n_chars)\n",
        "        full_preds = model.predict(x_seed, verbose=0)[0]\n",
        "        logits = full_preds[-1]\n",
        "        \n",
        "        probas, next_char_ind = get_token_proba(logits, temp)\n",
        "                \n",
        "        next_char = indices_token[int(str(next_char_ind))]\n",
        "        generated += next_char\n",
        "        seed_token += [next_char_ind]\n",
        "\n",
        "    gen=''   \n",
        "    for i in generated:\n",
        "      if i!='A':\n",
        "        gen+=i   \n",
        "    return gen\n",
        "\n",
        "def get_token_proba(preds, temp):\n",
        "    \n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temp\n",
        "    exp_preds = np.exp(preds)\n",
        "    \n",
        "    probas = exp_preds / np.sum(exp_preds)\n",
        "    char_ind = np.argmax(np.random.multinomial(1, probas, 1))\n",
        "    \n",
        "    return probas, char_ind\n",
        "\n",
        "def softmax(preds):\n",
        "    return np.exp(preds)/np.sum(np.exp(preds))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ah-vLXYtpm"
      },
      "source": [
        "Now let us look at few samples our model has generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otyRgyQvOElo",
        "outputId": "7ba3ec7f-f8d2-4b0b-c511-4b7941355a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.5,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCOc1ccccc1NC(=O)[C@@H]1CCN(C(=O)[C@@H]2CCC[NH+](Cc3ccccc3)C2)C[C@@H]1C)OE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTP1_llXYrH3",
        "outputId": "9dcff04d-99be-4e0e-dd1f-0226649e1342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.75,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GO=C(NCc1cccc(CN2C(=O)[C@@H](CCCN([C@H]3CCOO4)c2)c2ccccc2)c(=O)[nH]c1=OE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbbbrSpZEhm",
        "outputId": "76941398-6a8d-43d3-af12-8eb59f83cf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,1,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCc1ccc([C@]2(O)NC(=O)c2ccc(C3=O)Nc4ccccc3)n[(H]32=C[C@@H](c2ccccc2F)cc1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGaIYfLLmfdF"
      },
      "source": [
        "We can vary the temperature parameter to see the effect of variance on the generated sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R5UiQIKp0Yh"
      },
      "source": [
        "Temperature is a important parameter in sampling strategy. The high temperature sample displays greater linguistic variety, but the low temperature sample is more grammatically correct. Such is the world of temperature sampling - lowering the temperature allows you to focus on higher probability output sequences and smooth over deficiencies of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dygq5sZZIqO",
        "outputId": "b6666196-597d-4f70-bc68-92b5f6532c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.1,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC(=O)N1CCC(C(=O)N2CCC[C@@H](c3ccccc3)[C@@H]2c2ccccc2)[C@@H]1c1ccccc1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrUbu1LAZLlo",
        "outputId": "9b9fdaed-9fce-4d5a-ca8a-717390db0680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.2,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC(=O)N1CCC(C(=O)N2CCC[C@@H](c3ccccc3)[C@@H]2c2ccc(Cl)cc2)c2ccccc2[O-]E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2cYQljjajeS",
        "outputId": "994e50c6-503d-4b3f-d6d4-6f54cc237147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.3,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC1=C(C)CC(=O)N2CCC(C(=O)N3CCC[C@@H](C(=O)N4CCCC4)CC3)CC2)c2ccccc2[nH]1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQincy6fBB5",
        "outputId": "c27eac07-d5d4-4f7a-cf8b-43390a6674f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.4,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC[C@H]1CC(=O)N2CC[C@@H](C(=O)N3CCC(C(=O)Nc4ccccc4)CC3)C2)c2ccccc21E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrpbQP-Zfcr9",
        "outputId": "74fcb9e2-02b6-49c0-d246-ecf53d555c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.5,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCOc1ccc(-c2ccccc2)c(C[NH+]2CCC([C@@H]3CCCN3C(=O)Cc3ccc(F)cc3)CC2=O)c1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7U48kKnffiX",
        "outputId": "798e4f6a-ac28-4636-a39e-19a26e0cbc8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.6,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC1=C(NC(=O)[C@H]2CCCN2C(=O)C2CCO(C(=O)c3ccccc4)CC3)C2)C[C@@H]1C(=O)OCE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsz7JqDimJ95",
        "outputId": "025b602c-880e-4319-fac3-1301755a009b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.7,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC(=O)c1ccc2c(c1)=C(=O)C1=C(C)c3ccccc3=[NH+][C@@H]3c1ccccc3)cc(Cl)c2c1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si2dfQEDmYib",
        "outputId": "ac3f4204-51e5-436b-ee8b-ca9012420a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.8,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC[C@H]1CCCC[C@@H]1NC(=O)[C@@H]1CC(=O)N(C(C)(C)C)CC1)[C@@H](C)c1ccccc1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdCnr0UCma3A",
        "outputId": "38373821-d8f5-4e51-bbe5-d583980c9c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,0.9,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCC1(C)[C@H]2[NH3+])C[C@H](CN2C(=O)Nc3ccccc3)C[C@@H]2[NH+](CC[C@H]3C)C1E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oJG0vc0mN-C",
        "outputId": "ad264307-47d1-436f-ee99-39ca0a3c8a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model,1.0,'G','E',70,int_to_char,char_to_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'GCOc1cc(O[C@@H](C)Nc2nc(CC(=O)N3C[C@@H](C)O[C@H](c5ccccn4)C3)co2)ccc1OE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUI378szZbA0"
      },
      "source": [
        "* I guess, we can safely say our model really makes us convince that these molecules actually exist in nature!\n",
        "Most of the times it  gets all the syntax of SMILES right, with just 8 epochs ( 1.5 hr on Google Colab GPU : Tesla K80) like negative charge after Oxygen, positive charge with NH2, opening and closing brackets after starting a subsequence within a sequence.\n",
        " \n",
        "* We can train this model for a much longer time and we can expect more real like sequences. I'm told that authors have trained their network for 21 Hrs! albeit they had a much bigger datatset compared to what we have therefore they used a bigger network with more parameters as well, hence longer time to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBiiELVhiu4y"
      },
      "source": [
        "Acknowldegements:\n",
        "\n",
        "Huge thanks to Prof Dr [Schenider Gisbert](https://cadd.ethz.ch/people/gisbert_Schneider.html) , Researcher in Computer-assisted drug design at ETH Z√ºrich, Switzerland for providing access to his papers for better understanding of his research work without which this work would not have been possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBlsskHCwISH"
      },
      "source": [
        "**************************************************************************************************************"
      ]
    }
  ]
}
